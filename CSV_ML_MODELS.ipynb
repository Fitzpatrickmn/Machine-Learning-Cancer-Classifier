{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\joaog\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\joaog\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already up-to-date: imbalanced-learn in c:\\users\\joaog\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17 in c:\\users\\joaog\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --upgrade\n",
    "!pip install joblib\n",
    "!pip install imbalanced-learn --upgrade\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import (RandomOverSampler, SMOTE, ADASYN)\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd = pd.read_csv(\"data.csv\")\n",
    "numeric_data = nd.drop(columns=\"Unnamed: 32\")\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_num</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  diagnosis_num  radius_mean  texture_mean  \\\n",
       "0    842302         M              1        17.99         10.38   \n",
       "1    842517         M              1        20.57         17.77   \n",
       "2  84300903         M              1        19.69         21.25   \n",
       "3  84348301         M              1        11.42         20.38   \n",
       "4  84358402         M              1        20.29         14.34   \n",
       "\n",
       "   perimeter_mean  area_mean  smoothness_mean  compactness_mean  \\\n",
       "0          122.80     1001.0          0.11840           0.27760   \n",
       "1          132.90     1326.0          0.08474           0.07864   \n",
       "2          130.00     1203.0          0.10960           0.15990   \n",
       "3           77.58      386.1          0.14250           0.28390   \n",
       "4          135.10     1297.0          0.10030           0.13280   \n",
       "\n",
       "   concavity_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0          0.3001  ...         25.38          17.33           184.60   \n",
       "1          0.0869  ...         24.99          23.41           158.80   \n",
       "2          0.1974  ...         23.57          25.53           152.50   \n",
       "3          0.2414  ...         14.91          26.50            98.87   \n",
       "4          0.1980  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_data['diagnosis_num'] =  numeric_data['diagnosis'].apply(lambda x: 0 if x == 'B' else 1)\n",
    "numeric_data.columns\n",
    "numeric_data = numeric_data[['id', 'diagnosis', 'diagnosis_num', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis_num</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis_num  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0    842302              1        17.99         10.38          122.80   \n",
       "1    842517              1        20.57         17.77          132.90   \n",
       "2  84300903              1        19.69         21.25          130.00   \n",
       "3  84348301              1        11.42         20.38           77.58   \n",
       "4  84358402              1        20.29         14.34          135.10   \n",
       "\n",
       "   area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     1001.0          0.11840           0.27760          0.3001   \n",
       "1     1326.0          0.08474           0.07864          0.0869   \n",
       "2     1203.0          0.10960           0.15990          0.1974   \n",
       "3      386.1          0.14250           0.28390          0.2414   \n",
       "4     1297.0          0.10030           0.13280          0.1980   \n",
       "\n",
       "   concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0              0.14710  ...         25.38          17.33           184.60   \n",
       "1              0.07017  ...         24.99          23.41           158.80   \n",
       "2              0.12790  ...         23.57          25.53           152.50   \n",
       "3              0.10520  ...         14.91          26.50            98.87   \n",
       "4              0.10430  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_only = numeric_data.drop('diagnosis', axis=1)\n",
    "numeric_df = pd.DataFrame(numeric_only)\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = numeric_df['diagnosis_num']\n",
    "data = numeric_df.drop('diagnosis_num', axis=1)\n",
    "features = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tumors on data = 569\n",
      "Total Benign Tumors on data = 357\n",
      "Total Malignant Tumors on data = 212\n",
      "-----\n",
      "Percent Benign = 62.741652021089635\n",
      "Percent Malignant = 37.258347978910365\n"
     ]
    }
   ],
   "source": [
    "# EDA \n",
    "total_count_tumors = len(numeric_data)\n",
    "print(f'Total Tumors on data = {total_count_tumors}')\n",
    "total_count_benign = (numeric_data.diagnosis == 'B').sum()\n",
    "print(f'Total Benign Tumors on data = {total_count_benign}')\n",
    "total_count_malignant = (numeric_data.diagnosis == 'M').sum()\n",
    "print(f'Total Malignant Tumors on data = {total_count_malignant}')\n",
    "print(\"-----\")\n",
    "percent_benign = (total_count_benign/total_count_tumors)*100.00\n",
    "percent_malignant = (total_count_malignant/total_count_tumors)*100.00\n",
    "print(f\"Percent Benign = {percent_benign}\")\n",
    "print(f\"Percent Malignant = {percent_malignant}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the top 10 features according to the ```feature_selection``` from ```sklearn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature       Score\n",
      "28  concave points_worst  964.385393\n",
      "23       perimeter_worst  897.944219\n",
      "8    concave points_mean  861.676020\n",
      "21          radius_worst  860.781707\n",
      "3         perimeter_mean  697.235272\n",
      "24            area_worst  661.600206\n",
      "1            radius_mean  646.981021\n",
      "4              area_mean  573.060747\n",
      "7         concavity_mean  533.793126\n",
      "27       concavity_worst  436.691939\n"
     ]
    }
   ],
   "source": [
    "bestfeatures = SelectKBest(k=31)\n",
    "fit = bestfeatures.fit(data, target)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(data.columns)\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Feature','Score']\n",
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the top 10 features\n",
    "features_list_df = numeric_data[[\"concave points_worst\",\n",
    "\"perimeter_worst\",\n",
    "\"concave points_mean\",\n",
    "\"radius_worst\",\n",
    "\"perimeter_mean\",\n",
    "\"area_worst\",\n",
    "\"radius_mean\",\n",
    "\"area_mean\",\n",
    "\"concavity_mean\",\n",
    "\"concavity_worst\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERSAMPLING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 10) (398,)\n",
      "(171, 10) (171,)\n"
     ]
    }
   ],
   "source": [
    "# spliting the data on train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split (features_list_df, target, test_size = 0.30, random_state=21)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tumors on train data = 398\n",
      "Total Benign Tumors on train data = 250\n",
      "Total Malignant Tumors on train data = 148\n",
      "-----\n",
      "62.8140703517588\n",
      "37.185929648241206\n"
     ]
    }
   ],
   "source": [
    "# Count the training data\n",
    "total_count_tumors = len(y_train)\n",
    "print(f'Total Tumors on train data = {total_count_tumors}')\n",
    "total_count_benign = (y_train == 0).sum()\n",
    "print(f'Total Benign Tumors on train data = {total_count_benign}')\n",
    "total_count_malignant = (y_train == 1).sum()\n",
    "print(f'Total Malignant Tumors on train data = {total_count_malignant}')\n",
    "print(\"-----\")\n",
    "percent_benign = (total_count_benign/total_count_tumors)*100.00\n",
    "percent_malignant = (total_count_malignant/total_count_tumors)*100.00\n",
    "print(percent_benign)\n",
    "print(percent_malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset shape Counter({0: 250, 1: 148})\n"
     ]
    }
   ],
   "source": [
    "print('Original train dataset shape %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply oversampling models (RandomOverSampler, SMOTE, ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled RandomOverSampler train dataset shape Counter({0: 250, 1: 250})\n",
      "(500, 10) (500,)\n"
     ]
    }
   ],
   "source": [
    "# Random Over Sampler Model\n",
    "ros = RandomOverSampler(random_state=21)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "print('Resampled RandomOverSampler train dataset shape %s' % Counter(y_ros))\n",
    "print (X_ros.shape, y_ros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled SMOTE train dataset shape Counter({0: 250, 1: 250})\n",
      "(500, 10) (500,)\n"
     ]
    }
   ],
   "source": [
    "# SMOTE: Synthetic Minority Oversampling Technique Model\n",
    "sm = SMOTE(random_state=21)\n",
    "X_sm, y_sm = sm.fit_resample(X_train, y_train)\n",
    "print('Resampled SMOTE train dataset shape %s' % Counter(y_sm))\n",
    "print (X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled ADASYN train dataset shape Counter({1: 254, 0: 250})\n",
      "(504, 10) (504,)\n"
     ]
    }
   ],
   "source": [
    "# ADASYN: Adaptive Synthetic Sampling Model\n",
    "ada = ADASYN(random_state=21)\n",
    "X_ada, y_ada = ada.fit_resample(X_train, y_train)\n",
    "print('Resampled ADASYN train dataset shape %s' % Counter(y_ada))\n",
    "print (X_ada.shape, y_ada.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling models comparison SMOTE VS ADASYN.\n",
    "\n",
    "SMOTE: It finds the n-nearest neighbors in the minority class for each of the samples in the class. Then it draws a line between the the neighbors an generates random points on the lines.\n",
    "\n",
    "ADASYN:  Works as SMOTE, but with a minor improved. After creating the sample it adds a random small values to the points. In other words instead of all the sample being linearly correlated to the parent they have a little more variance in them, been a bit scattered.\n",
    "\n",
    "To take advantage of this smaller variation on the new data, we will use the ADASYN model to oversample the data (X_ada, y_ada)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data using the ```StandardScaler```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "X_scaler = StandardScaler().fit(X_ada)\n",
    "X_train_scaled = X_scaler.transform(X_ada)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.05148514851486 %\n"
     ]
    }
   ],
   "source": [
    "# import and train the model\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, validation_curve\n",
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "kfold = KFold(n_splits=5,random_state=21, shuffle=True)\n",
    "cv_results = cross_val_score(logreg, X_train_scaled, y_ada, cv=kfold)\n",
    "print (cv_results.mean()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Logistic Regression Data Score: 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "# apply the model \n",
    "\n",
    "logreg.fit(X_test_scaled, y_test)\n",
    "print(f\"Testing Logistic Regression Data Score: {logreg.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, train and apply the model\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_SVC = SVC()\n",
    "model_SVC.fit(X_train_scaled, y_ada)\n",
    "prediction_SVC = model_SVC.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data SVC Score: 0.9325396825396826\n",
      "Testing Data SVC Score: 0.9649122807017544\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Benign        0.97      0.97      0.97       107\n",
      "   Malignant       0.95      0.95      0.95        64\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data SVC Score: {model_SVC.score(X_train_scaled, y_ada)}\")\n",
    "print(f\"Testing Data SVC Score: {model_SVC.score(X_test_scaled, y_test)}\\n\")\n",
    "print(classification_report(y_test, prediction_SVC,\n",
    "                            target_names=['Benign ', 'Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GridSearchCV to Hyperparameter Tuning the model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_SVC = {'C': [1, 5, 10, 50, 100],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid_SVC = GridSearchCV(model_SVC, param_grid_SVC, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.871, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.871, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.832, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.584, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.610, total=   0.0s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.941, total=   0.0s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.911, total=   0.0s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.921, total=   0.0s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.782, total=   0.0s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.810, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.941, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.881, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.850, total=   0.0s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.911, total=   0.0s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.911, total=   0.0s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.950, total=   0.0s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.911, total=   0.0s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.860, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.941, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.911, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.921, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.782, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.911, total=   0.0s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.921, total=   0.0s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.950, total=   0.0s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.881, total=   0.0s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.860, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.911, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.950, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.911, total=   0.0s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.860, total=   0.0s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.931, total=   0.0s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.931, total=   0.0s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.960, total=   0.0s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.921, total=   0.0s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.870, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.921, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.911, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.941, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.881, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.850, total=   0.0s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.911, total=   0.0s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.921, total=   0.0s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.950, total=   0.0s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.911, total=   0.0s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.860, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.901, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.960, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.870, total=   0.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.921, total=   0.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.931, total=   0.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.950, total=   0.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.921, total=   0.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.870, total=   0.0s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.911, total=   0.0s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.921, total=   0.0s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.950, total=   0.0s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.911, total=   0.0s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.860, total=   0.0s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.931, total=   0.0s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.931, total=   0.0s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.960, total=   0.0s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.921, total=   0.0s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.870, total=   0.0s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.931, total=   0.0s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.950, total=   0.0s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.870, total=   0.0s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.921, total=   0.0s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.931, total=   0.0s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.950, total=   0.0s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.950, total=   0.0s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.880, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.901, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.921, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=100, gamma=0.0001, score=0.960, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.921, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.870, total=   0.0s\n",
      "[CV] C=100, gamma=0.0005 .............................................\n",
      "[CV] ................. C=100, gamma=0.0005, score=0.921, total=   0.0s\n",
      "[CV] C=100, gamma=0.0005 .............................................\n",
      "[CV] ................. C=100, gamma=0.0005, score=0.931, total=   0.0s\n",
      "[CV] C=100, gamma=0.0005 .............................................\n",
      "[CV] ................. C=100, gamma=0.0005, score=0.950, total=   0.0s\n",
      "[CV] C=100, gamma=0.0005 .............................................\n",
      "[CV] ................. C=100, gamma=0.0005, score=0.921, total=   0.0s\n",
      "[CV] C=100, gamma=0.0005 .............................................\n",
      "[CV] ................. C=100, gamma=0.0005, score=0.870, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.921, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.931, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.950, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.931, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.860, total=   0.0s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n",
      "[CV] .................. C=100, gamma=0.005, score=0.921, total=   0.0s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n",
      "[CV] .................. C=100, gamma=0.005, score=0.931, total=   0.0s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n",
      "[CV] .................. C=100, gamma=0.005, score=0.960, total=   0.0s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n",
      "[CV] .................. C=100, gamma=0.005, score=0.960, total=   0.0s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n",
      "[CV] .................. C=100, gamma=0.005, score=0.880, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10, 50, 100],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_SVC.fit(X_train_scaled, y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GridSeachCV Parameters {'C': 100, 'gamma': 0.005}\n",
      "Best GridSeachCV result 0.9304554455445544\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best GridSeachCV Parameters {grid_SVC.best_params_}\")\n",
    "print(f\"Best GridSeachCV result {grid_SVC.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the best SCV model\n",
    "bestSVC_model = SVC(C=100, kernel='linear', gamma=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data bestSVC_model Score: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#Best SVC model results\n",
    "bestSVC_model.fit(X_test_scaled, y_test)\n",
    "print(f\"Testing Data bestSVC_model Score: {bestSVC_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# # One-hot encoding y to run a Neural Network Model.\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_ada)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "print(y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model and create the layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples\n",
      "Epoch 1/100\n",
      "504/504 - 0s - loss: 1.0519 - accuracy: 0.2877\n",
      "Epoch 2/100\n",
      "504/504 - 0s - loss: 0.9381 - accuracy: 0.3036\n",
      "Epoch 3/100\n",
      "504/504 - 0s - loss: 0.8438 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "504/504 - 0s - loss: 0.7586 - accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "504/504 - 0s - loss: 0.6807 - accuracy: 0.5238\n",
      "Epoch 6/100\n",
      "504/504 - 0s - loss: 0.6148 - accuracy: 0.7679\n",
      "Epoch 7/100\n",
      "504/504 - 0s - loss: 0.5545 - accuracy: 0.8373\n",
      "Epoch 8/100\n",
      "504/504 - 0s - loss: 0.5056 - accuracy: 0.8532\n",
      "Epoch 9/100\n",
      "504/504 - 0s - loss: 0.4631 - accuracy: 0.8591\n",
      "Epoch 10/100\n",
      "504/504 - 0s - loss: 0.4283 - accuracy: 0.8651\n",
      "Epoch 11/100\n",
      "504/504 - 0s - loss: 0.3992 - accuracy: 0.8651\n",
      "Epoch 12/100\n",
      "504/504 - 0s - loss: 0.3749 - accuracy: 0.8631\n",
      "Epoch 13/100\n",
      "504/504 - 0s - loss: 0.3552 - accuracy: 0.8611\n",
      "Epoch 14/100\n",
      "504/504 - 0s - loss: 0.3384 - accuracy: 0.8690\n",
      "Epoch 15/100\n",
      "504/504 - 0s - loss: 0.3246 - accuracy: 0.8690\n",
      "Epoch 16/100\n",
      "504/504 - 0s - loss: 0.3126 - accuracy: 0.8750\n",
      "Epoch 17/100\n",
      "504/504 - 0s - loss: 0.3024 - accuracy: 0.8790\n",
      "Epoch 18/100\n",
      "504/504 - 0s - loss: 0.2937 - accuracy: 0.8810\n",
      "Epoch 19/100\n",
      "504/504 - 0s - loss: 0.2859 - accuracy: 0.8810\n",
      "Epoch 20/100\n",
      "504/504 - 0s - loss: 0.2791 - accuracy: 0.8829\n",
      "Epoch 21/100\n",
      "504/504 - 0s - loss: 0.2731 - accuracy: 0.8849\n",
      "Epoch 22/100\n",
      "504/504 - 0s - loss: 0.2679 - accuracy: 0.8869\n",
      "Epoch 23/100\n",
      "504/504 - 0s - loss: 0.2635 - accuracy: 0.8889\n",
      "Epoch 24/100\n",
      "504/504 - 0s - loss: 0.2593 - accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "504/504 - 0s - loss: 0.2557 - accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "504/504 - 0s - loss: 0.2526 - accuracy: 0.8909\n",
      "Epoch 27/100\n",
      "504/504 - 0s - loss: 0.2499 - accuracy: 0.8909\n",
      "Epoch 28/100\n",
      "504/504 - 0s - loss: 0.2471 - accuracy: 0.8909\n",
      "Epoch 29/100\n",
      "504/504 - 0s - loss: 0.2449 - accuracy: 0.8889\n",
      "Epoch 30/100\n",
      "504/504 - 0s - loss: 0.2426 - accuracy: 0.8889\n",
      "Epoch 31/100\n",
      "504/504 - 0s - loss: 0.2409 - accuracy: 0.8909\n",
      "Epoch 32/100\n",
      "504/504 - 0s - loss: 0.2391 - accuracy: 0.8909\n",
      "Epoch 33/100\n",
      "504/504 - 0s - loss: 0.2377 - accuracy: 0.8929\n",
      "Epoch 34/100\n",
      "504/504 - 0s - loss: 0.2362 - accuracy: 0.8948\n",
      "Epoch 35/100\n",
      "504/504 - 0s - loss: 0.2348 - accuracy: 0.8948\n",
      "Epoch 36/100\n",
      "504/504 - 0s - loss: 0.2337 - accuracy: 0.8968\n",
      "Epoch 37/100\n",
      "504/504 - 0s - loss: 0.2326 - accuracy: 0.9008\n",
      "Epoch 38/100\n",
      "504/504 - 0s - loss: 0.2315 - accuracy: 0.9008\n",
      "Epoch 39/100\n",
      "504/504 - 0s - loss: 0.2306 - accuracy: 0.9008\n",
      "Epoch 40/100\n",
      "504/504 - 0s - loss: 0.2297 - accuracy: 0.9008\n",
      "Epoch 41/100\n",
      "504/504 - 0s - loss: 0.2288 - accuracy: 0.9087\n",
      "Epoch 42/100\n",
      "504/504 - 0s - loss: 0.2279 - accuracy: 0.9087\n",
      "Epoch 43/100\n",
      "504/504 - 0s - loss: 0.2273 - accuracy: 0.9067\n",
      "Epoch 44/100\n",
      "504/504 - 0s - loss: 0.2263 - accuracy: 0.9067\n",
      "Epoch 45/100\n",
      "504/504 - 0s - loss: 0.2258 - accuracy: 0.9107\n",
      "Epoch 46/100\n",
      "504/504 - 0s - loss: 0.2250 - accuracy: 0.9107\n",
      "Epoch 47/100\n",
      "504/504 - 0s - loss: 0.2242 - accuracy: 0.9107\n",
      "Epoch 48/100\n",
      "504/504 - 0s - loss: 0.2240 - accuracy: 0.9107\n",
      "Epoch 49/100\n",
      "504/504 - 0s - loss: 0.2232 - accuracy: 0.9127\n",
      "Epoch 50/100\n",
      "504/504 - 0s - loss: 0.2222 - accuracy: 0.9127\n",
      "Epoch 51/100\n",
      "504/504 - 0s - loss: 0.2215 - accuracy: 0.9127\n",
      "Epoch 52/100\n",
      "504/504 - 0s - loss: 0.2210 - accuracy: 0.9127\n",
      "Epoch 53/100\n",
      "504/504 - 0s - loss: 0.2203 - accuracy: 0.9127\n",
      "Epoch 54/100\n",
      "504/504 - 0s - loss: 0.2197 - accuracy: 0.9127\n",
      "Epoch 55/100\n",
      "504/504 - 0s - loss: 0.2190 - accuracy: 0.9147\n",
      "Epoch 56/100\n",
      "504/504 - 0s - loss: 0.2186 - accuracy: 0.9127\n",
      "Epoch 57/100\n",
      "504/504 - 0s - loss: 0.2179 - accuracy: 0.9147\n",
      "Epoch 58/100\n",
      "504/504 - 0s - loss: 0.2172 - accuracy: 0.9147\n",
      "Epoch 59/100\n",
      "504/504 - 0s - loss: 0.2168 - accuracy: 0.9147\n",
      "Epoch 60/100\n",
      "504/504 - 0s - loss: 0.2161 - accuracy: 0.9147\n",
      "Epoch 61/100\n",
      "504/504 - 0s - loss: 0.2155 - accuracy: 0.9147\n",
      "Epoch 62/100\n",
      "504/504 - 0s - loss: 0.2150 - accuracy: 0.9147\n",
      "Epoch 63/100\n",
      "504/504 - 0s - loss: 0.2144 - accuracy: 0.9147\n",
      "Epoch 64/100\n",
      "504/504 - 0s - loss: 0.2140 - accuracy: 0.9147\n",
      "Epoch 65/100\n",
      "504/504 - 0s - loss: 0.2134 - accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "504/504 - 0s - loss: 0.2129 - accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "504/504 - 0s - loss: 0.2124 - accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "504/504 - 0s - loss: 0.2117 - accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "504/504 - 0s - loss: 0.2111 - accuracy: 0.9187\n",
      "Epoch 70/100\n",
      "504/504 - 0s - loss: 0.2107 - accuracy: 0.9187\n",
      "Epoch 71/100\n",
      "504/504 - 0s - loss: 0.2102 - accuracy: 0.9187\n",
      "Epoch 72/100\n",
      "504/504 - 0s - loss: 0.2095 - accuracy: 0.9187\n",
      "Epoch 73/100\n",
      "504/504 - 0s - loss: 0.2090 - accuracy: 0.9187\n",
      "Epoch 74/100\n",
      "504/504 - 0s - loss: 0.2085 - accuracy: 0.9187\n",
      "Epoch 75/100\n",
      "504/504 - 0s - loss: 0.2080 - accuracy: 0.9187\n",
      "Epoch 76/100\n",
      "504/504 - 0s - loss: 0.2075 - accuracy: 0.9187\n",
      "Epoch 77/100\n",
      "504/504 - 0s - loss: 0.2071 - accuracy: 0.9187\n",
      "Epoch 78/100\n",
      "504/504 - 0s - loss: 0.2066 - accuracy: 0.9187\n",
      "Epoch 79/100\n",
      "504/504 - 0s - loss: 0.2060 - accuracy: 0.9187\n",
      "Epoch 80/100\n",
      "504/504 - 0s - loss: 0.2054 - accuracy: 0.9187\n",
      "Epoch 81/100\n",
      "504/504 - 0s - loss: 0.2049 - accuracy: 0.9187\n",
      "Epoch 82/100\n",
      "504/504 - 0s - loss: 0.2044 - accuracy: 0.9187\n",
      "Epoch 83/100\n",
      "504/504 - 0s - loss: 0.2038 - accuracy: 0.9187\n",
      "Epoch 84/100\n",
      "504/504 - 0s - loss: 0.2034 - accuracy: 0.9187\n",
      "Epoch 85/100\n",
      "504/504 - 0s - loss: 0.2029 - accuracy: 0.9187\n",
      "Epoch 86/100\n",
      "504/504 - 0s - loss: 0.2022 - accuracy: 0.9187\n",
      "Epoch 87/100\n",
      "504/504 - 0s - loss: 0.2017 - accuracy: 0.9187\n",
      "Epoch 88/100\n",
      "504/504 - 0s - loss: 0.2012 - accuracy: 0.9187\n",
      "Epoch 89/100\n",
      "504/504 - 0s - loss: 0.2007 - accuracy: 0.9187\n",
      "Epoch 90/100\n",
      "504/504 - 0s - loss: 0.2003 - accuracy: 0.9187\n",
      "Epoch 91/100\n",
      "504/504 - 0s - loss: 0.1997 - accuracy: 0.9187\n",
      "Epoch 92/100\n",
      "504/504 - 0s - loss: 0.1993 - accuracy: 0.9187\n",
      "Epoch 93/100\n",
      "504/504 - 0s - loss: 0.1987 - accuracy: 0.9187\n",
      "Epoch 94/100\n",
      "504/504 - 0s - loss: 0.1983 - accuracy: 0.9206\n",
      "Epoch 95/100\n",
      "504/504 - 0s - loss: 0.1978 - accuracy: 0.9206\n",
      "Epoch 96/100\n",
      "504/504 - 0s - loss: 0.1973 - accuracy: 0.9206\n",
      "Epoch 97/100\n",
      "504/504 - 0s - loss: 0.1969 - accuracy: 0.9206\n",
      "Epoch 98/100\n",
      "504/504 - 0s - loss: 0.1964 - accuracy: 0.9206\n",
      "Epoch 99/100\n",
      "504/504 - 0s - loss: 0.1959 - accuracy: 0.9206\n",
      "Epoch 100/100\n",
      "504/504 - 0s - loss: 0.1955 - accuracy: 0.9206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28c4efeea08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile and train the model\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.1523783787300712, Accuracy: 0.9415204524993896\n"
     ]
    }
   ],
   "source": [
    "# apply the model to the test data\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=3)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandonForest Data Score: 1.0\n",
      "Testing RandonForest Data Score: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# import the model \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_scaled, y_ada)\n",
    "\n",
    "print(f\"Training RandonForest Data Score: {rf.score(X_train_scaled, y_ada)}\")\n",
    "print(f\"Testing RandonForest Data Score: {rf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GridSearchCV to Hyperparameter Tuning the model\n",
    "\n",
    "param_grid_rf = {'n_estimators': [250, 300, 350],'max_depth': [125, 150, 175]}\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=125, n_estimators=250, score=0.941, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=125, n_estimators=250, score=0.941, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=125, n_estimators=250, score=0.950, total=   0.2s\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=250, score=0.931, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=250, score=0.880, total=   0.2s\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.931, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.950, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.950, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.931, total=   0.4s\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.880, total=   0.3s\n",
      "[CV] max_depth=125, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=350, score=0.941, total=   0.4s\n",
      "[CV] max_depth=125, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=350, score=0.931, total=   0.4s\n",
      "[CV] max_depth=125, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=350, score=0.960, total=   0.4s\n",
      "[CV] max_depth=125, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=350, score=0.931, total=   0.4s\n",
      "[CV] max_depth=125, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=350, score=0.880, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=250, score=0.941, total=   0.2s\n",
      "[CV] max_depth=150, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=250, score=0.950, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=250, score=0.950, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=250, score=0.931, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=250, score=0.880, total=   0.2s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=300, score=0.931, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=300, score=0.950, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=300, score=0.950, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=300, score=0.941, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=300, score=0.880, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=350, score=0.941, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=350, score=0.941, total=   0.4s\n",
      "[CV] max_depth=150, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=350, score=0.950, total=   0.4s\n",
      "[CV] max_depth=150, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=350, score=0.931, total=   0.3s\n",
      "[CV] max_depth=150, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=150, n_estimators=350, score=0.880, total=   0.4s\n",
      "[CV] max_depth=175, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=250, score=0.931, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=250, score=0.970, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=250, score=0.960, total=   0.2s\n",
      "[CV] max_depth=175, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=250, score=0.941, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=250, score=0.880, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=300, score=0.931, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=300, score=0.941, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=300, score=0.960, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=300, score=0.931, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=300, score=0.880, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=350, score=0.941, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=350, score=0.941, total=   0.4s\n",
      "[CV] max_depth=175, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=350, score=0.950, total=   0.3s\n",
      "[CV] max_depth=175, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=350, score=0.931, total=   0.4s\n",
      "[CV] max_depth=175, n_estimators=350 .................................\n",
      "[CV] ..... max_depth=175, n_estimators=350, score=0.880, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [125, 150, 175],\n",
       "                         'n_estimators': [250, 300, 350]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train_scaled, y_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Parameters {'max_depth': 175, 'n_estimators': 250}\n",
      "Best RandomForest result 0.9363960396039603\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best RandomForest Parameters {grid_rf.best_params_}\")\n",
    "print(f\"Best RandomForest result {grid_rf.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(max_depth=175, n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RandomForest Data Score: 0.9473684210526315\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Benign        0.96      0.95      0.96       107\n",
      "   Malignant       0.92      0.94      0.93        64\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.94      0.95      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(X_train_scaled, y_ada)\n",
    "prediction_rf = best_rf.predict(X_test_scaled)\n",
    "print(f\"Testing RandomForest Data Score: {best_rf.score(X_test_scaled, y_test)}\\n\")\n",
    "\n",
    "print(classification_report(y_test, prediction_rf,\n",
    "                            target_names=['Benign ', 'Malignant']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
